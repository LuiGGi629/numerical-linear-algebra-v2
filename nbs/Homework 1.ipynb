{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due on Thurs, 5/31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider the polynomial $p(x) = (x-2)^9 = x^9 - 18x^8 + 144x^7 - 672x^6 + 2016x^5 - 4032x^4 + 5376x^3 - 4608x^2 + 2304x - 512$\n",
    "\n",
    "  a. Plot $p(x)$ for $x=1.920,\\,1.921,\\,1.922,\\ldots,2.080$ evaluating $p$ via its coefficients $1,\\,,-18,\\,144,\\ldots$\n",
    "\n",
    "  b. Plot the same plot again, now evaluating $p$ via the expression $(x-2)^9$.\n",
    "\n",
    "  c. Explain the difference.\n",
    "  \n",
    "  *(The numpy method linspace will be useful for this)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many different double-precision numbers are there?  Express your answer using powers of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Using the updated [Numbers Every Programmer Should Know](https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html), how much longer does a main memory reference take than an L1 cache look-up?  How much longer does a disk seek take than a main memory reference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Main memory reference is 100 times slower than an L1 cache.\n",
    "- Disk seek? That's really slow! 2_000_000 ns $\\approx$ 2ms\n",
    "\n",
    "**Key take-away**: Each successive memory type is (at least) an order of magnitude worse than the one before it.  Disk seeks are **very slow**.\n",
    "\n",
    "<img src=\"images/l1_cache_vs_main_memory.png\" style=\"width: 100%\"/>\n",
    "\n",
    "<img src=\"images/disk_seek.png\" style=\"width: 100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. From the Halide Video, what are 4 ways to traverse a 2d array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Using the animations below ([source](https://www.youtube.com/watch?v=3uiEyEKji0M)), explain what the benefits and pitfalls of each approach. Green squares indicate that a value is being read; red indicates a value is being written. Your answers should be longer in length (give more detail) than just two words.\n",
    "\n",
    "  a. <img src=\"images/Halide1.gif\" alt=\"Halide\" style=\"width: 70%\"/>\n",
    "  \n",
    "We read 3 values from the input to compute a single value of the blur in x stage. We haven't even started writing to the output yet. **poor locality**. By the time blur in y stage goes to read some intermidate data, it's probably been evicted from cache.\n",
    "  \n",
    "  b. <img src=\"images/Halide2.gif\" alt=\"Halide\" style=\"width: 70%\"/>\n",
    "  \n",
    "Here we compute three values of blur in x by reading 9 values from the input and we immediately use that to compute one values of the output. So here we get maximum locality - we're using data as soon as it's available without giving it any time to be evicted from cache. We're doing a lot of wasted work. **redundant recompute**. Each point in blur x is redundantly recomputed three times. \n",
    "  \n",
    "  c. <img src=\"images/Halide3.gif\" alt=\"Halide\" style=\"width: 70%\"/>\n",
    "  \n",
    "Notice that we've allocated enough memory to keep around all of the intermediate stage, and we're not throwing away values as we go. That means when we get the second scan line we can start reusing values that we computed earlier. We have locality and we're not doing any redundant work. We've introduced a serial dependence in scanlines of the output. We're relying on the fact that we have computed scanline n-1 before we can stop computing scaline n. This means that we can't paralellize across scanlines with this strategy. With the previous two strategies we could. **poor parallelism**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Prove that if $A = Q B Q^T$ for some orthnogonal matrix $Q$, the $A$ and $B$ have the same singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. What is the *stochastic* part of *stochastic gradient descent*?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
